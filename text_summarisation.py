# -*- coding: utf-8 -*-
"""npl1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vGva2et9bPZT2KyjdEWB4I6w6YaXaYUU
"""

import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation

stopwords=list(STOP_WORDS)

nlp=spacy.load('en_core_web_sm')

text=" Best chocolate A1 delivery Very bad product Good Nice product  everyone liked it thank you flipcart Good Bad Nice Super Best Arsh love Priya Melting chocolate   Love it Delicious  Will order again Wow Good Price high Ilove it Best Nice Good Good product Goog Good nice Thank you Good   Nice Super iteam Good Yummy   Good   Wow   Waste product Please don t buy this product Good products Worth it   Good Good Really awesome product Yummmmmy I like it Very good good super Best Just wow   Bad quality Thank you   Very good quality and the taste is awesome  Love to order it again Average Nice Good Good Leakage Yummy   Good I love it Happy with silk purchase  I got this in best condition Seller gives this choclate with ice pack for better condition of chocolates Good very good Good geniune  long Expiry date  Nice Thats a multipurpose chocklet"

doc=nlp(text)

tokens= [token.text for token in doc]
print(tokens)

# punctuation=punctuation
punctuation

word_frequencies = {}
for word in doc:
  if word.text.lower() not in stopwords:
    if word.text.lower() not in punctuation:
      if word.text not in word_frequencies.keys():
        word_frequencies[word.text]=1
      else:
        word_frequencies[word.text] += 1

print(word_frequencies)

max_frequency = max(word_frequencies.values())
max_frequency

for word in word_frequencies.keys():
  word_frequencies[word] = word_frequencies[word]/max_frequency

print(word_frequencies)

# sentence tokenisation

sentence_tokens = [sent for sent in doc.sents]
print(sentence_tokens)

sentence_scores = {}
for sent in sentence_tokens:
  for word in sent:
    if word.text.lower() in word_frequencies.keys():
      if word.text.lower() not in punctuation:
        if sent not in sentence_scores.keys():
          sentence_scores[sent]=word_frequencies[word.text.lower()]
        else:
          sentence_scores[sent] += word_frequencies[word.text.lower()]
print(sentence_scores)

from heapq import nlargest

select_lenght = int(len(sentence_tokens)*0.3)
select_lenght

summary = nlargest(select_lenght,sentence_scores,key =sentence_scores.get)

summary

final_summary = [word.text for word in summary]

summary = ' '.join(final_summary)

print(text)

print(summary)

# len(text)

# len(summary)